{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Network\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp networks.representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ShortcutProjection(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.bn(self.conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=out_channels,\n",
    "            kernel_size=3, stride=stride, padding=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels, out_channels=out_channels,\n",
    "            kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = ShortcutProjection(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                stride=stride\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = self.shortcut(x)\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        return self.act2(out + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BottleneckResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, bottleneck_channels: int, out_channels: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=bottleneck_channels,\n",
    "            kernel_size=1, stride=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=bottleneck_channels)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=bottleneck_channels, out_channels=bottleneck_channels,\n",
    "            kernel_size=3, stride=stride, padding=1\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=bottleneck_channels)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=bottleneck_channels, out_channels=out_channels,\n",
    "            kernel_size=1, stride=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = ShortcutProjection(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                stride=stride\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.act3 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = self.shortcut(x)\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.act2(self.bn2(self.conv2(out)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        return self.act3(out + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class RepresentationNetwork(nn.Module):\n",
    "#     # def __init__(self, in_channels: int, bottleneck_channels: int, out_channels: int, stride: int):\n",
    "#     #     super().__init__()\n",
    "#     #     self.conv1 = nn.Conv2d(\n",
    "#     #         in_channels, bottleneck_channels,\n",
    "#     #         kernel_size=1, stride=1\n",
    "#     #     )\n",
    "#     #     self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
    "#     #     self.act1 = nn.ReLU()\n",
    "#     #     self.conv2 = nn.Conv2d(\n",
    "#     #         bottleneck_channels, bottleneck_channels,\n",
    "#     #         kernel_size=3, stride=stride, padding=1\n",
    "#     #     )\n",
    "#     #     self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "#     #     self.act2 = nn.ReLU()\n",
    "#     def __init__(\n",
    "#         self, n_blocks: List[int], n_channels: List[int],\n",
    "#         bottlenecks: Optional[List[int]] = None,\n",
    "#         img_channels: int = 3, first_kernel_size: int = 7\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         assert len(n_blocks) == len(n_channels)\n",
    "#         assert bottlenecks is not None or len(bottlenecks) == len(n_channels)\n",
    "        \n",
    "#         self.conv = nn.Conv2d(img_channels, n_channels[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation Model\n",
    "\n",
    "$h(o^i) = s^i$\n",
    "\n",
    "output the hidden state of the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RepresentationNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self, img_channels: int, n_blocks: int, n_channels: int,\n",
    "        first_kernel_size: int, bottlenecks: Optional[List[int]] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert len(n_blocks) == len(n_channels)\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=img_channels, out_channels=n_channels[0],\n",
    "            kernel_size=first_kernel_size, stride=1, padding=first_kernel_size//2\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(n_channels[0])\n",
    "\n",
    "        blocks = []\n",
    "        prev_channels = n_channels[0]\n",
    "\n",
    "        for i, channels in enumerate(n_channels):\n",
    "            stride = 2 if len(blocks) == 0 else 1\n",
    "\n",
    "            if bottlenecks is None:\n",
    "                blocks.append(ResidualBlock(\n",
    "                    in_channels=prev_channels, out_channels=channels,\n",
    "                    stride=stride\n",
    "                ))\n",
    "            else:\n",
    "                blocks.append(BottleneckResidualBlock(\n",
    "                    in_channels=prev_channels, bottleneck_channels=bottlenecks[i],\n",
    "                    out_channels=channels, stride=stride\n",
    "                ))\n",
    "\n",
    "            prev_channels = channels\n",
    "\n",
    "            for _ in range(n_blocks[i] - 1):\n",
    "                if bottlenecks is None:\n",
    "                    \n",
    "                    blocks.append(ResidualBlock(\n",
    "                        in_channels=channels, out_channels=channels,\n",
    "                        stride=1\n",
    "                    ))\n",
    "                else:\n",
    "                    blocks.append(BottleneckResidualBlock(\n",
    "                        in_channels=channels, bottleneck_channels=bottlenecks[i],\n",
    "                        out_channels=channels, stride=1\n",
    "                    ))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.bn(self.conv(x))\n",
    "        x = self.blocks(x)\n",
    "        x = x.view(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "        return x.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation = RepresentationNetwork(\n",
    "#     img_channels=3, n_blocks=[3, 3, 3], n_channels=[16, 32, 64],\n",
    "#     first_kernel_size=7, bottlenecks=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation.conv.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation(torch.randn(5, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
