{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from muzero.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# muzero\n",
    "\n",
    "> Implement MuZero from scratch [WORK IN PROGRESS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install -r requirements\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MuZero"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Representation function - $h_{\\theta}(o_1, o_2,...o_t)$: It takes the history of observations and produces a hidden state $s_o$ of the observations\n",
    "\n",
    "- Prediction function - $f_{\\theta}(s^k)$: It takes the hidden state of the observation and predicts the policy $\\pi^k$ and the value $v^k$\n",
    "\n",
    "- Dynamic function - $g_{\\theta}(s^{k-1}, a^k) = r^k, s^k$: It takes the current state and an action, it predicts the next state and reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components\n",
    "Monte Carlo Tree Search (MCTS: to guide the exploration of the game state space and select the most promising actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- A replay buffer share between agents\n",
    "- Monte Carlo Tree Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "Resources that i used to implement MuZero\n",
    "- MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model | RL Paper explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
