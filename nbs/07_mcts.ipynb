{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search \n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: It takes the current game state\n",
    "- Step 2: It runs multiple random game simulations starting from this game state\n",
    "- Step 3: For each simulation, the final state is evaluated by a score\n",
    "- Step 4: It only remembers the next move of each simulation and accumulates the score for that move\n",
    "- Step 5: After the simulation is done, it returns the next move with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "from typing import List, Tuple, Optional, Union, Dict, Literal\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "from muzero.chess.game import get_init_board, place_piece, get_valid_moves, is_board_full, is_win"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context of Go, each board of the game is a node, each node contains who turn to play..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ucb_score(parent, child):\n",
    "    prior_score = child.prior_prob * math.sqrt(parent.visits) / (child.visits + 1)\n",
    "    \n",
    "    if child.visits > 0:\n",
    "        value_score = child.value / child.visits\n",
    "    else:\n",
    "        value_score = 0\n",
    "    \n",
    "    return value_score + prior_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Player(Enum):\n",
    "    BLACK = 1\n",
    "    WHITE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Node:\n",
    "    def __init__(self, prior_prob: float, player_turn: Player, state: torch.Tensor):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            prior_prob (float): _description_\n",
    "            player_turn (_type_): _description_\n",
    "            state (_type_): _description_\n",
    "        \n",
    "        Attr:\n",
    "            children (Dict[int, Node]): a dictionary of child nodes, indexed by action\n",
    "            value (Union[int, float]): the total reward value of all visits to this node\n",
    "            visits (int): the number of times this node has been visited\n",
    "        \"\"\"\n",
    "        self.prior_prob: float = prior_prob\n",
    "        self.player_turn = player_turn\n",
    "        self.state: torch.Tensor = state\n",
    "        \n",
    "        self.children: Dict[int, Node] = {}\n",
    "        self.value: Union[int, float] = 0\n",
    "        self.visits: int = 0\n",
    "    \n",
    "    def get_next_player_turn(self, current_turn: Player) -> Player:\n",
    "        next_player_turn = Player.BLACK if current_turn == Player.WHITE else Player.WHITE\n",
    "        return next_player_turn\n",
    "    \n",
    "    def expand(self, action_probs: List[float]):\n",
    "        for action, prob in enumerate(action_probs):\n",
    "            if prob > 0:\n",
    "                next_player_turn = self.get_next_player_turn(self.player_turn)\n",
    "                next_state = place_piece(board=self.state, player=next_player_turn.value, action=action)\n",
    "                \n",
    "                self.children[action] = Node(\n",
    "                    prior_prob=prob,\n",
    "                    player_turn=next_player_turn,\n",
    "                    state=next_state\n",
    "                )\n",
    "    \n",
    "    def select_child(self):\n",
    "        max_score = -9999\n",
    "        \n",
    "        for action, child in self.children.items():\n",
    "            score = ucb_score(self, child)\n",
    "            \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                selected_action = action\n",
    "                selected_child = child\n",
    "        \n",
    "        return selected_action, selected_child\n",
    "\n",
    "    # def ucb_score(self) -> Union[int, float]:\n",
    "    #     \"\"\"The UCB score of a node.\"\"\"\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go_env = gym.make('gym_go:go-v0', size=7, komi=0, reward_method='real')\n",
    "# go_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from muzero.chess.view_board import render\n",
    "\n",
    "board = np.array(\n",
    "    [[0, -1, -1, -1, 1, 0, -1],\n",
    "     [0, 1, -1, 1, 1, 0, 1],\n",
    "     [-1, 1, -1, 1, 1, 0, -1],\n",
    "     [1, -1, 1, -1, -1, 0, -1],\n",
    "     [-1, -1, 1, -1, 1, 1, -1],\n",
    "     [-1, 1, 1, -1, 1, -1, 1]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Node(\n",
    "    prior_prob=0, player_turn=1, state=torch.tensor(board)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.expand(\n",
    "    action_probs=[0.5, 0, 0, 0, 0, 0.5, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <__main__.Node>, 5: <__main__.Node>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render(root.children[0].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dummy_model_predict(board):\n",
    "\tvalue_head = 0.5\n",
    "\taction_probs = [0.5, 0, 0, 0, 0, 0.5, 0]\n",
    "\treturn value_head, action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(n_simulations):\n",
    "    node = root\n",
    "    \n",
    "    search_path = [node]\n",
    "    \n",
    "    while len(node.children) > 0:\n",
    "        # select the next child until we reach an unexpaned node\n",
    "        action, node = node.select_child()\n",
    "        search_path.append(node)\n",
    "    \n",
    "    value: Optional[Union[int, float]] = None\n",
    "    \n",
    "    # calculate the value once we reach a leaf node\n",
    "    if is_board_full(board=node.state):\n",
    "        value = 0\n",
    "    elif is_win(board=node.state, player=1):\n",
    "        value = 1\n",
    "    elif is_win(board=node.state, player=-1):\n",
    "        value = -1\n",
    "     \n",
    "    if value is None:\n",
    "        # if game is not over, get value from network and expand\n",
    "        # TODO: why game not over? if you continue expand, then one point the game must end?\n",
    "        value, action_probs = dummy_model_predict(node.state)\n",
    "        \n",
    "        node.expand(action_probs)\n",
    "    \n",
    "    # back up the value\n",
    "    for node in search_path:\n",
    "        node.value += value\n",
    "        node.visits += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prior_prob': 0.5,\n",
       " 'player_turn': <Player.WHITE: -1>,\n",
       " 'state': array([[ 0, -1, -1, -1,  1,  0, -1],\n",
       "        [-1,  1, -1,  1,  1,  0,  1],\n",
       "        [-1,  1, -1,  1,  1,  0, -1],\n",
       "        [ 1, -1,  1, -1, -1,  0, -1],\n",
       "        [-1, -1,  1, -1,  1,  1, -1],\n",
       "        [-1,  1,  1, -1,  1, -1,  1]]),\n",
       " 'children': {0: <__main__.Node>,\n",
       "  5: <__main__.Node>},\n",
       " 'value': 79.5,\n",
       " 'visits': 98}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[5].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <__main__.Node>, 5: <__main__.Node>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
